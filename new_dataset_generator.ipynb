{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6881172e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7ef720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import librosa\n",
    "import mido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97529a10",
   "metadata": {},
   "source": [
    "# Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22098447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar:\n",
    "    def __init__(self, total, length=40):\n",
    "        self.total = total\n",
    "        self.length = length\n",
    "        self.current = 0\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def update(self, step=1):\n",
    "        self.current += step\n",
    "        progress = self.current / self.total\n",
    "        filled_length = int(self.length * progress)\n",
    "        bar = '=' * filled_length + '-' * (self.length - filled_length)\n",
    "        if self.current == 1 or self.current == self.total or filled_length > int(self.length * ((self.current - step) / self.total)):\n",
    "            print(f'\\r|{bar}| {self.current}/{self.total} ({progress:.2%})  {time.time() - self.start_time:.1f}s', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce0a774",
   "metadata": {},
   "source": [
    "# Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04752e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator():\n",
    "    def __init__(\n",
    "        self,\n",
    "        wav_mid_df: pd.DataFrame,\n",
    "        output_path: str,\n",
    "        chunk_size: int = 128,\n",
    "        step_size: int = 64,\n",
    "        sample_rate: int = 12_800,\n",
    "        n_fft: int = 2048,\n",
    "        hop_length: int = 256,\n",
    "        n_mels: int = 512,\n",
    "        override: bool = False,\n",
    "    ):\n",
    "        self.wav_mid_df = wav_mid_df\n",
    "        self.output_path = output_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.step_size = step_size\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.time_per_frame = hop_length / sample_rate\n",
    "\n",
    "        if override and os.path.exists(self.output_path):\n",
    "            os.remove(self.output_path)\n",
    "\n",
    "    def _get_spectogram(self, wave_path: str) -> np.ndarray:\n",
    "        samples, sr = librosa.load(wave_path, sr=self.sample_rate)\n",
    "\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(\n",
    "            y=samples, sr=sr, n_fft=self.n_fft, hop_length=self.hop_length, n_mels=self.n_mels)\n",
    "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "        return mel_spectrogram_db\n",
    "\n",
    "    def _get_message_df(self, midi_path) -> pd.DataFrame:\n",
    "        mid = mido.MidiFile(midi_path)\n",
    "        note_msg = map(lambda x: (x, x.time), mid.tracks[-1])\n",
    "        note_df = pd.DataFrame(note_msg, columns=['other', 'time'])\n",
    "\n",
    "        note_df['time'] = note_df['time'].cumsum()\n",
    "        note_df = note_df[note_df['other'].apply(\n",
    "            lambda x: x.type == 'note_on')]\n",
    "        note_df['note'] = note_df['other'].apply(lambda x: x.note)\n",
    "        note_df['velocity'] = note_df['other'].apply(lambda x: x.velocity)\n",
    "        note_df = note_df.drop(columns=['other']).reset_index(drop=True)\n",
    "        return note_df\n",
    "    \n",
    "    def _get_spec_chunk(self, spec: np.ndarray, i: int) -> np.ndarray:\n",
    "        spec_chunk = spec[:, i * self.step_size : i * self.step_size + self.chunk_size]\n",
    "        return spec_chunk\n",
    "\n",
    "    def _get_midi_chunk(self, midi: pd.DataFrame, i: int) -> np.ndarray:\n",
    "        start_time = i * self.step_size * self.time_per_frame * 1000\n",
    "        end_time = (i * self.step_size + self.chunk_size) * self.time_per_frame * 1000\n",
    "\n",
    "        midi_chunk = midi[(midi['time'] >= start_time) & (midi['time'] < end_time)].copy()\n",
    "        midi_chunk['time'] = midi_chunk['time'] - int(start_time)\n",
    "        return midi_chunk.to_numpy()\n",
    "    \n",
    "    def _get_chunk_meta(self, midi_chunk: np.ndarray):\n",
    "        if midi_chunk.shape[0] == 0:\n",
    "            return np.array([0, 0, 0])\n",
    "        meta = [midi_chunk[:, 1].min(), midi_chunk[:, 1].max(), len(midi_chunk)]\n",
    "        return meta\n",
    "    \n",
    "    def _get_chunks(self, wave_path: str, midi_path: str) -> pd.DataFrame:\n",
    "        spec = self._get_spectogram(wave_path)\n",
    "        midi = self._get_message_df(midi_path)\n",
    "\n",
    "        length = int((spec.shape[1] - self.chunk_size) / self.step_size)\n",
    "        chunks = []\n",
    "        for i in range(length):\n",
    "            spec_chunk = self._get_spec_chunk(spec, i)\n",
    "            midi_chunk = self._get_midi_chunk(midi, i)\n",
    "            \n",
    "            chunks.append((spec_chunk, midi_chunk))\n",
    "        return pd.DataFrame(chunks, columns=['spec', 'midi'])\n",
    "\n",
    "    def _save_chunk(self, spec_chunk: np.ndarray, midi_chunk: np.ndarray, piece_name: str):\n",
    "        with h5py.File(self.output_path, 'a') as h5:\n",
    "            if piece_name not in h5:\n",
    "                piece_group = h5.create_group(piece_name)\n",
    "            else:\n",
    "                piece_group = h5[piece_name]\n",
    "\n",
    "            chunk_idx = len(piece_group)\n",
    "            chunk_group = piece_group.create_group(f'chunk_{chunk_idx}')\n",
    "\n",
    "            chunk_group.create_dataset('image', data=spec_chunk, compression='gzip')\n",
    "            chunk_group.create_dataset('midi', data=midi_chunk, compression='gzip')\n",
    "            chunk_group.create_dataset('meta', data=self._get_chunk_meta(midi_chunk), compression='gzip')\n",
    "\n",
    "    def generate(self):\n",
    "        output_dir = os.path.dirname(self.output_path)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        progress_bar = ProgressBar(len(self.wav_mid_df))\n",
    "        for i, (idx, row) in enumerate(self.wav_mid_df.iterrows()):\n",
    "            wave_path = row['wav']\n",
    "            midi_path = row['midi']\n",
    "            piece_name = os.path.basename(wave_path).split('.')[0]\n",
    "\n",
    "            if os.path.exists(wave_path) and os.path.exists(midi_path):\n",
    "                chunks = self._get_chunks(wave_path, midi_path)\n",
    "                for _, (spec_chunk, midi_chunk) in chunks.iterrows():\n",
    "                    self._save_chunk(spec_chunk, midi_chunk, piece_name)\n",
    "            else:\n",
    "                print(f\"File not found: {wave_path} or {midi_path}\")\n",
    "\n",
    "            progress_bar.update()\n",
    "\n",
    "\n",
    "    # def _getSimpleSpectogram(self, wave_file: str, notes: list[int]):\n",
    "    #     spec = self.getSpectogram(wave_file)\n",
    "    #     mel_frequencies = librosa.mel_frequencies(n_mels=spec.shape[0], fmin=0, fmax=self.sample_rate / 2)\n",
    "\n",
    "    #     note_freqs = pd.read_csv('note_freqs.csv').values\n",
    "    #     indexes = np.array([mel_frequencies[np.abs(mel_frequencies - val).argmin()] for val in note_freqs])\n",
    "    #     indexes = np.array([np.where(mel_frequencies == val)[0][0] for val in indexes])\n",
    "    #     indexes = indexes[notes]\n",
    "\n",
    "    #     spec = spec[indexes]\n",
    "    #     return spec, mel_frequencies[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e9da0",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99187f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'wav_midi.csv'\n",
    "h5_path = f'dataset.h5'\n",
    "folder_path = 'waves'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df['wav'] = df['wav'].apply(lambda x: os.path.join(folder_path, x))\n",
    "df['midi'] = df['midi'].apply(lambda x: os.path.join(folder_path, x))\n",
    "# df = df.sample(2)\n",
    "\n",
    "dataset_gen = DatasetGenerator(df, h5_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68d29a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|========================================| 2/2 (100.00%)  3.4s"
     ]
    }
   ],
   "source": [
    "dataset_gen.generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
