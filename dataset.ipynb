{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc3b18e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "01406e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f990d02",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c30f3349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>midi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/252_0.png</td>\n",
       "      <td>dataset/252_0.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/252_1.png</td>\n",
       "      <td>dataset/252_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/252_2.png</td>\n",
       "      <td>dataset/252_2.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/252_3.png</td>\n",
       "      <td>dataset/252_3.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/252_4.png</td>\n",
       "      <td>dataset/252_4.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>dataset/556_57.png</td>\n",
       "      <td>dataset/556_57.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>dataset/556_58.png</td>\n",
       "      <td>dataset/556_58.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>dataset/556_59.png</td>\n",
       "      <td>dataset/556_59.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>dataset/556_60.png</td>\n",
       "      <td>dataset/556_60.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>dataset/556_61.png</td>\n",
       "      <td>dataset/556_61.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                midi\n",
       "0     dataset/252_0.png   dataset/252_0.csv\n",
       "1     dataset/252_1.png   dataset/252_1.csv\n",
       "2     dataset/252_2.png   dataset/252_2.csv\n",
       "3     dataset/252_3.png   dataset/252_3.csv\n",
       "4     dataset/252_4.png   dataset/252_4.csv\n",
       "..                  ...                 ...\n",
       "507  dataset/556_57.png  dataset/556_57.csv\n",
       "508  dataset/556_58.png  dataset/556_58.csv\n",
       "509  dataset/556_59.png  dataset/556_59.csv\n",
       "510  dataset/556_60.png  dataset/556_60.csv\n",
       "511  dataset/556_61.png  dataset/556_61.csv\n",
       "\n",
       "[512 rows x 2 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df['image'] = df['image'].apply(lambda x: os.path.join('dataset', x))\n",
    "df['midi'] = df['midi'].apply(lambda x: os.path.join('dataset', x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c9d8b",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c979fb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112, 22, 1, 122, 32, 1, 142, 22, 0]\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, time_count=260, note_count=100, vel_count=2):\n",
    "        self.val_to_velo = {i: i for i in range(vel_count)}\n",
    "        self.val_to_note = {i: i + vel_count for i in range(note_count)}\n",
    "        self.val_to_time = {i: i + vel_count + note_count for i in range(time_count)}\n",
    "        \n",
    "        self.id_to_token = {\n",
    "            **{self.val_to_velo[i]: f'velo_{i}' for i in self.val_to_velo},\n",
    "            **{self.val_to_note[i]: f'note_{i}' for i in self.val_to_note},\n",
    "            **{self.val_to_time[i]: f'time_{i}' for i in self.val_to_time}\n",
    "        }\n",
    "        \n",
    "        self.token_to_id = {v: k for k, v in self.id_to_token.items()}\n",
    "\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        return [self.token_to_id[token] for token in tokens]\n",
    "\n",
    "\n",
    "    def decode(self, ids):\n",
    "        return [self.id_to_token[id] for id in ids]\n",
    "    \n",
    "\n",
    "    def tuple_to_ids(self, tuple):\n",
    "        return [self.val_to_time[tuple[0]], self.val_to_note[tuple[1]], self.val_to_velo[tuple[2]]]\n",
    "    \n",
    "\n",
    "    def tuple_list_to_ids(self, tuple_list):\n",
    "        l = np.array([self.tuple_to_ids(t) for t in tuple_list]).flatten().tolist()\n",
    "        return l\n",
    "\n",
    "\n",
    "t = Tokenizer()\n",
    "# for k in t.id_to_token:\n",
    "    # print(f'{str(k).rjust(3)}   {str(t.id_to_token[k])}')\n",
    "print(t.tuple_list_to_ids([(10, 20, 1), (20, 30, 1), (40, 20, 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb465d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dfc614c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([185,  50,   1, 185,  62,   1, 196,  38,   1, 197,  26,   1, 204,  26,\n",
       "          0, 205,  50,   0, 207,  38,   0, 208,  62,   0, 251,  62,   1, 260,\n",
       "         69,   1, 263,  62,   0, 266,  72,   1, 281,  78,   1, 282,  86,   1,\n",
       "        293,  86,   0, 303,  90,   1, 303,  98,   1, 310,  90,   0, 317,  96,\n",
       "          1, 320,  98,   0, 323,  92,   1, 329,  96,   0, 333,  93,   1, 334,\n",
       "         90,   1, 335,  92,   0, 336,  91,   1, 337,  93,   0, 338,  91,   0,\n",
       "        340,  90,   0, 340,  86,   1, 342,  78,   0, 344,  72,   0, 345,  69,\n",
       "          0, 346,  86,   0, 349,  84,   1, 355,  82,   1])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FrameDataset(Dataset):\n",
    "    def __init__(self, image_midi_path_pairs, tokenizer):\n",
    "        self.df = image_midi_path_pairs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.df.iloc[idx]['image']\n",
    "        midi_path = self.df.iloc[idx]['midi']\n",
    "        \n",
    "        image = Image.open(image_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        midi = pd.read_csv(midi_path)\n",
    "        midi['time'] = midi['time'] // 10\n",
    "        midi['velocity'] = (midi['velocity'] > 0).astype(int)\n",
    "        midi = midi.values.tolist()\n",
    "        midi = self.tokenizer.tuple_list_to_ids(midi)\n",
    "        midi = torch.tensor(midi, dtype=torch.long)\n",
    "        \n",
    "        return image, midi\n",
    "\n",
    "\n",
    "dataset = FrameDataset(df, Tokenizer())\n",
    "el = dataset[0]\n",
    "print(el[0].shape)\n",
    "el[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
